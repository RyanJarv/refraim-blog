

# **A Strategic and Technical Analysis of AI Chunking Methodologies for Source Code Vulnerability Detection**

## **Introduction: The Critical Role of Preprocessing in AI-Driven Code Security**

### **Situating Chunking within the Moiuu a Gğvgyvyyyyy youvvuvuiyiyùuuijujujjujujuiuj**

### **I**

### [**U.K.uj**](http://U.K.uj)

### **Jjjijjjajjbb b d**

### **Poisono look ł n  llòì much**

### **M  dern AI-Powered SAST Pipeline**

The field of Static Application Security Testing (SAST) is undergoing a paradigm shift, driven by the advanced reasoning capabilities of Large Language Models (LLMs). Traditional SAST tools, while effective, often rely on rigid, pattern-based rules and can struggle with the semantic nuances of complex code, leading to high false-positive rates and an inability to detect novel or intricate vulnerability patterns. LLMs promise to overcome these limitations by bringing a deeper, more contextual understanding to code analysis. However, the efficacy of any LLM-based system is fundamentally predicated on the quality and structure of the data it receives.1 In this context, the process of "chunking"—breaking down vast code repositories into smaller, manageable segments for LLM analysis—emerges not as a mere preliminary step, but as the foundational architectural decision that dictates the performance, accuracy, and reliability of the entire vulnerability scanning pipeline.4  
For an AI-powered vulnerability scanner, particularly one architected in a Retrieval-Augmented Generation (RAG) style where an initial LLM pass identifies potential issues and a second process retrieves context to verify exploitability, chunking is paramount. It defines the fundamental unit of analysis, directly influencing the "signal-to-noise" ratio of the information presented to the model.7 An optimal chunking strategy ensures that each segment of code sent to the LLM is a coherent, self-contained unit, maximizing the model's ability to detect subtle vulnerabilities. Conversely, a suboptimal strategy can fragment critical information, rendering the LLM effectively blind to entire classes of security flaws.

### **The Core Challenge: Maximizing Semantic and Syntactic Context for LLM Analysis**

The central engineering challenge in designing a chunking strategy for source code is resolving the inherent tension between the finite context window of an LLM and the expansive, interconnected nature of a codebase.7 LLMs can only process a limited number of tokens at once; feeding them oversized chunks can dilute relevant information with noise, exceed model limits, and increase latency and cost.11 On the other hand, creating chunks that are too small risks severing the critical contextual links that define a vulnerability.12  
In the domain of source code, "context" is a multi-layered construct. It includes:

1. **Lexical Context:** The immediate surrounding tokens and lines of code.  
2. **Syntactic Context:** The code's structural grammar, such as the scope of a function, the boundaries of a class, the nesting of conditional blocks, and the relationships between parent and child nodes in its Abstract Syntax Tree (AST).  
3. **Semantic Context:** The logical flow of the program, particularly the data flow that traces user-controllable input from its source (e.g., an HTTP request) through various transformations and conditional paths to a potentially dangerous sink (e.g., a database query or a file system API call).

A naive chunking approach that severs these contextual threads forces the LLM to waste a significant portion of its analytical capacity simply trying to reconstruct the broken program logic. It is akin to asking a security expert to review a function that has been arbitrarily cut in half. The analysis becomes unreliable, if not impossible. The chunking strategy, therefore, functions as a form of "attention scaffolding." It is an engineered mechanism designed to guide the LLM's focus. A well-designed strategy presents the model with a coherent, pre-structured "scene" for analysis, allowing it to dedicate its full cognitive resources to identifying the security implications of the code's logic. A poorly designed strategy, by contrast, presents a fragmented and confusing input, imposing a high cognitive load on the model just to parse the broken code before any security analysis can even begin. This has profound implications for both the accuracy and the computational efficiency of the scanner.  
Furthermore, each chunking strategy creates a specific "aperture" or window through which the scanner views the code. The size, shape, and placement of this aperture determine which types of vulnerability patterns are visible. A strategy might create an aperture perfectly suited for spotting a single-line misconfiguration, like a hardcoded API key, but be structurally incapable of capturing the full pattern of a complex data-flow vulnerability, such as Path Traversal, which may span multiple functions and hundreds of lines of code. The choice of chunking strategy, therefore, defines the theoretical limits of the scanner's detection capabilities.

### **Overview of the Six Analyzed Strategies and the Report's Objective**

This report provides a definitive technical analysis of six distinct chunking strategies, evaluating their suitability for a high-fidelity, AI-powered vulnerability scanner. These strategies are organized along a spectrum of increasing complexity and context-awareness:

* **Structure-Agnostic Strategies:** Fixed-Size Chunking and Sliding Window Chunking, which operate on raw text without regard for code structure.  
* **Heuristic Strategies:** Recursive Chunking, which uses textual separators as a proxy for structure.  
* **Structure-Aware Strategies:** Semantic/Content-Aware Chunking (specifically AST-based) and Embedding-Based Chunking, which deeply analyze the code's syntactic and semantic properties.  
* **Autonomous Strategies:** Agentic Chunking, which leverages an LLM to make dynamic, task-specific chunking decisions.

The objective of this report is to move beyond high-level definitions and provide a rigorous, in-depth analysis of how each strategy interacts with the unique challenges of source code analysis. It will furnish the technical and strategic guidance necessary to select and implement the optimal chunking architecture for detecting a wide range of vulnerabilities across multiple programming languages, forming the bedrock of a truly effective AI-driven security tool.

## **Foundational Chunking Strategies: Speed and Simplicity vs. Contextual Integrity**

The most basic chunking strategies operate directly on the raw text of the source code, prioritizing implementation simplicity and computational speed. While appealing for their low overhead, they are fundamentally "structure-agnostic," treating code as a simple sequence of characters. This disregard for the syntactic and semantic structure of the programming language introduces significant risks that can undermine the entire analysis pipeline.

### **A. Fixed-Size Chunking**

#### **Mechanism**

Fixed-size chunking is the most straightforward and common approach to data segmentation.9 It involves dividing the source code file into segments of a predetermined length, typically measured in characters or, more appropriately for LLMs, tokens.2 For example, a 10,000-token source file might be split into twenty 500-token chunks. This method is often recommended as an initial baseline for experimentation due to its simplicity.9

#### **Benefits**

The primary advantages of fixed-size chunking lie in its operational efficiency and predictability.

* **Simplicity and Speed:** The logic for implementation is minimal, requiring little more than a character or token counter. This results in extremely fast preprocessing with low computational overhead, making it suitable for scenarios where speed is the absolute priority.2  
* **Predictable Performance:** Because every chunk is of a uniform size, resource allocation for downstream processes like embedding and LLM analysis becomes highly predictable. This consistency can simplify the design of batch processing systems and help manage computational costs without unexpected spikes.13

#### **Drawbacks**

Despite its simplicity, fixed-size chunking is fraught with severe drawbacks when applied to source code, stemming from its complete ignorance of programming language syntax.

* **Severe Context Splitting:** This is the strategy's fatal flaw. By imposing arbitrary boundaries based on character or token count, it inevitably severs logical code units. A single chunk might end in the middle of a function definition, a class declaration, a for loop, or even a variable name.13 This phenomenon, known in other data processing domains as the "boundary-shift problem," is particularly damaging to code analysis, as the syntactic and semantic integrity of the code is destroyed.21  
* **Impact on Vulnerability Detection:** For the majority of vulnerabilities targeted by the scanner, this context splitting is catastrophic. Vulnerabilities that depend on data flow—such as SQL Injection, Cross-Site Scripting (XSS), Command Injection, and Path Traversal—are defined by the path data takes from a source to a sink. With fixed-size chunking, the source (e.g., user\_input \= request.GET.get('filename') in Python) could easily land in one chunk, while the sink (e.g., with open('/data/' \+ user\_input, 'r') as f:) lands in the next. Presented with these fragments in isolation, the LLM has no way to connect the tainted input to the dangerous operation and will fail to identify the vulnerability. This leads to a high rate of false negatives for the most critical vulnerability classes.

The consequences of this fundamental flaw propagate through the entire analysis system in a cascade of failures. The initial act of creating a syntactically broken chunk leads to the generation of a noisy and contextually meaningless embedding. During the second-phase exploitability check, a query for context will retrieve these meaningless embeddings, providing the verification LLM with irrelevant or incomplete information. This can lead to two equally undesirable outcomes: a false negative, where a real vulnerability is missed because its constituent parts were never analyzed together, or a false positive, where the LLM hallucinates a vulnerability because it lacks the necessary context to see why the code is, in fact, safe. The initial architectural simplicity of fixed-size chunking thus creates profound downstream complexity and unreliability.

#### **When to Use**

Given its severe limitations, fixed-size chunking is **generally not recommended** for any form of deep or reliable vulnerability analysis. Its application should be restricted to a very narrow set of use cases:

* **Highly Localized "Stateless" Checks:** It may be marginally acceptable for scanning for patterns that are self-contained within a single line or a very small, contiguous block of code. Examples include searching for hardcoded secrets (e.g., API\_KEY \= "..."), deprecated function usage, or simple security misconfigurations in a configuration file.  
* **Performance Baselines:** It serves as a useful experimental baseline. By comparing the results of a fixed-size chunking scan against more sophisticated methods, a development team can quantitatively measure the value and accuracy improvement gained from context-aware strategies.3

### **B. Sliding Window Chunking**

#### **Mechanism**

Sliding window chunking is a direct enhancement of the fixed-size method, designed to mitigate its most glaring flaw: the hard-cutting of context at chunk boundaries. The strategy works by moving a fixed-size "window" across the code with a specified "stride" or step size that is smaller than the window itself. This creates a series of overlapping chunks.14 For example, with a window size of 500 tokens and a stride of 400 tokens, each new chunk will repeat the last 100 tokens of the previous chunk. A common overlap size is between 10% and 20% of the total chunk size.1

#### **Benefits**

The primary advantage of this approach is the preservation of context around the chunk boundaries.

* **Context Preservation at Boundaries:** The overlap ensures that a statement or small logical block that would have been split by a fixed-size boundary is likely to appear, in its entirety, in at least one of the two adjacent chunks. This reduces the chance of missing localized context and improves the overall coherence of the data presented to the LLM.1  
* **Increased Recall:** By creating redundancy, the sliding window increases the probability that a complete vulnerability pattern will be captured within a single chunk. If a critical line of code falls exactly at a boundary, the overlap ensures it is included in the preceding or subsequent chunk, increasing the chances of detection.15

#### **Drawbacks**

While an improvement, the sliding window approach introduces its own set of trade-offs and does not fully solve the underlying problem.

* **Increased Computational Cost and Redundancy:** The creation of overlapping data significantly increases the total number of chunks that must be processed, embedded, stored, and analyzed. This redundancy leads to higher storage costs, increased processing time, and greater computational load on the LLM, potentially slowing down the entire scan.13  
* **Still Fundamentally Arbitrary:** The core issue remains: the chunk boundaries are still determined by a fixed size, not by the logical structure of the code. While the overlap can save a single statement from being split, it cannot prevent the fragmentation of larger structures like functions, classes, or complex conditional blocks. It is a patch, not a fundamental solution.19

This strategy can create an "illusion of progress." It appears to solve the boundary-splitting problem, but it introduces new, more subtle challenges. The increased data volume means the LLM may waste significant resources analyzing multiple, highly similar chunks of non-vulnerable code. Furthermore, during the exploitability verification stage, the retrieval system might pull two overlapping but still incomplete chunks as context. This can confuse the verification LLM, which is now presented with two slightly different views of the same fragmented code, potentially leading to inconsistent or contradictory findings for the same vulnerability.

#### **When to Use**

Sliding window chunking represents a pragmatic compromise between the raw speed of fixed-size chunking and the need for better context preservation. It is a suitable choice when:

* A simple, computationally inexpensive approach is required, but the risk of context loss from standard fixed-size chunking is deemed unacceptable.  
* The scanner is targeting vulnerabilities where the source and sink are typically in close proximity but could be separated by an arbitrary boundary. A simple reflected XSS, where user input is taken on one line and echoed back within the next few lines, is a good example. The overlap would ensure this small pattern remains intact for the LLM to analyze.

### **C. Recursive Chunking**

#### **Mechanism**

Recursive chunking is a more sophisticated, heuristic-based strategy that attempts to align chunk boundaries with the natural structure of the text. It operates using a prioritized, hierarchical list of separators. The algorithm first tries to split the text using the highest-priority separator (e.g., a double newline, \\n\\n, often representing a paragraph or block). If the resulting chunks are still too large, it recursively applies the next separator in the list (e.g., a single newline, \\n) to those oversized chunks, and so on, down to spaces and finally individual characters.4  
For source code, this can be adapted. Advanced frameworks like LangChain provide language-aware RecursiveCharacterTextSplitter implementations that can use a priority list of separators relevant to specific programming languages, such as class definitions, function definitions, and then newlines.27

#### **Benefits**

This hierarchical approach offers a significant improvement in coherence over purely size-based methods.

* **Improved Semantic Coherence:** By attempting to split along natural delimiters in the code, such as newlines, which often correspond to statement endings, or double newlines, which might separate functions, this method produces chunks that are more likely to be logically and semantically coherent.1 It tries to keep paragraphs, sentences, and words together as much as possible.  
* **A Better Balance:** It provides a good default balance between maintaining some degree of structural integrity and controlling the final chunk size. For many types of semi-structured text, including well-formatted code, it is a marked improvement over structure-agnostic approaches.1

#### **Drawbacks**

The primary weakness of recursive chunking is that it is ultimately a heuristic. It uses textual patterns as a proxy for true syntactic structure, which can be unreliable.

* **Heuristic and Unreliable for Code:** The strategy's effectiveness is entirely dependent on the code's formatting and the chosen separators. It can be easily defeated by unconventional coding styles, complex nested logic that isn't cleanly separated by newlines, or in languages where whitespace is not syntactically significant (e.g., C++, Java, JavaScript). It is still a surface-level analysis that does not parse or understand the code's grammar.2  
* **Variable Chunk Sizes:** The recursive process can lead to chunks of highly variable sizes. A file might contain one very large function that gets chunked recursively down to the character level, resulting in many small, fragmented chunks, alongside another small function that fits entirely within the size limit and becomes a single, larger chunk. This inconsistency can be inefficient for batch processing and embedding.19

#### **When to Use**

Recursive chunking is often the best choice among the foundational strategies and can serve as a strong general-purpose default when the computational cost of full parsing is a constraint.

* As a "better-than-fixed-size" default, especially for initial or rapid scans in a CI/CD pipeline where a full, deep audit is not required.  
* It is particularly effective for scripting languages where formatting is syntactically significant and consistent, such as Python or Ruby. In these languages, indentation and newlines are strong indicators of logical blocks, aligning well with the strategy's heuristic approach.  
* It is also highly suitable for analyzing structured configuration files like YAML, JSON, or Dockerfiles, where the newline and indentation-based chunking logic naturally corresponds to the hierarchical structure of the data.

## **Structure-Aware Chunking: The Key to High-Fidelity Analysis**

To overcome the fundamental limitations of text-based heuristics, a vulnerability scanner must adopt strategies that understand the code as a structured program, not just a sequence of characters. Structure-aware chunking methods parse the source code to comprehend its syntactic and semantic properties, enabling the creation of chunks that represent complete, logical units of analysis. These advanced techniques are computationally more intensive but are essential for achieving the high degree of accuracy required for reliable vulnerability detection.

### **A. Semantic/Content-Aware Chunking (AST-Based)**

#### **Mechanism**

This strategy represents a fundamental leap from text processing to true program analysis. Instead of splitting text, it first parses the source code into an Abstract Syntax Tree (AST). An AST is a hierarchical data structure, used internally by compilers and interpreters, that represents the code's syntactic structure in a tree format.31 Each node in the tree corresponds to a construct in the code, such as a function declaration, an  
if statement, a for loop, or a variable assignment.  
Chunking is then performed by traversing this tree and creating chunks that correspond to specific, meaningful nodes. For vulnerability analysis, the most logical units are typically entire functions, methods, or classes.34 This approach guarantees that every chunk is a syntactically complete and logically self-contained unit of code, precisely respecting the boundaries defined by the programming language's grammar.9

#### **Benefits**

The advantages of AST-based chunking are profound and directly address the core requirements of vulnerability scanning.

* **Preservation of Syntactic and Semantic Integrity:** This is the strategy's most critical benefit. By creating chunks that align with logical code boundaries (e.g., an entire function), it preserves the complete context necessary for data-flow and control-flow analysis. For vulnerabilities like SQL Injection, Path Traversal, Command Injection, and many forms of XSS, the ability to trace a variable from its source (user input) to its sink (a dangerous API call) within a single, coherent unit is paramount.20 An AST-based chunk encapsulates this entire potential path, making the complete vulnerability pattern visible to the LLM in one analytical operation. This capability dramatically increases the probability of detection and significantly reduces the rate of false negatives compared to structure-agnostic methods. This is because providing a syntactically complete unit allows the LLM to perform a form of abstract interpretation or "mental execution" of the code. It can reason about the flow of data through conditional branches and transformations, effectively simulating the program's behavior to identify vulnerabilities—a task that is impossible with fragmented, syntactically invalid chunks.38  
* **Cross-Language Consistency:** The concept of an AST is fundamental to compiler design and is applicable to virtually all modern programming languages. Universal parsing tools like tree-sitter provide robust parsers for a wide array of languages, including all those specified in the user query (\*.py, \*.java, \*.go, \*.js, etc.).32 This allows for the implementation of a single, consistent, and highly effective chunking methodology that is portable across the entire diverse codebase, ensuring uniform quality of analysis regardless of the language being scanned.34  
* **Empirically Proven Superiority:** Academic and industry research consistently demonstrates that structure-aware chunking methods significantly outperform syntax-agnostic heuristics for a wide range of code intelligence tasks, including code generation and retrieval.20 For the specialized task of vulnerability detection, this superiority is even more pronounced, as the syntactic and semantic integrity of the code is not just beneficial but strictly necessary for accurate analysis.

#### **Drawbacks**

The power of AST-based chunking comes at the cost of increased complexity and computational overhead.

* **Computational Cost and Complexity:** Parsing an entire codebase into ASTs is a more computationally intensive process than simple text splitting. It requires invoking language-specific parsers for each file, which consumes more CPU time and memory during the initial ingestion phase.39 The engineering effort to implement, integrate, and maintain a suite of parsers for all target languages is also non-trivial.  
* **Handling Very Large Logical Units:** A potential challenge arises when a single logical unit, such as a monolithic function or a massive class, exceeds the LLM's context window. In such cases, a pure function-level chunking approach is insufficient. The strategy must be enhanced with a recursive fallback mechanism. For example, if a function node is too large, the algorithm can recursively descend the AST to chunk it into its constituent, but still syntactically meaningful, sub-units, such as loops, conditional blocks, or sequences of statements.20

#### **When to Use**

Given its unparalleled ability to preserve the context required for security analysis, AST-based chunking should be considered the **default and strongly recommended foundational strategy** for any serious, high-accuracy AI-powered vulnerability scanner.

* It is indispensable for detecting any vulnerability class that involves data flow, control flow, or state changes that span more than a few lines of code. This includes the vast majority of high-impact vulnerabilities, such as SQL Injection, XSS, CSRF, Path Traversal, Command Injection, Insecure Deserialization, XXE, SSRF, and Broken Access Control.

### **B. Embedding-Based Chunking**

#### **Mechanism**

Embedding-based chunking, often referred to as a form of semantic chunking, operates on the conceptual meaning of the code rather than its strict syntactic structure. The process typically involves several steps:

1. The code is first broken down into small, atomic units, such as individual lines or sentences.  
2. An embedding model—ideally one specifically pre-trained on source code, like GraphCodeBERT or CodeT5—is used to convert each atomic unit into a high-dimensional numerical vector (an embedding) that captures its semantic meaning.41  
3. The algorithm then iterates through these sequential embeddings, calculating the cosine similarity (a measure of semantic relatedness) between adjacent units.  
4. It groups contiguous units that have high similarity. When a significant drop in similarity is detected—indicating a shift in topic or logical function—it creates a boundary and starts a new chunk.1

#### **Benefits**

This strategy's strength lies in its ability to group code based on its functional purpose, revealing relationships that are not strictly defined by syntax.

* **Grouping by Semantic Topic:** This approach excels at creating chunks that are thematically coherent. In a source code context, this means it can group together statements and expressions that contribute to a single, high-level task (e.g., "user authentication logic" or "database connection setup"), even if this logic is spread across several lines or simple blocks.5  
* **Detecting Vulnerabilities Across Non-Contiguous Code:** This is the unique and powerful capability of embedding-based chunking. It has the potential to identify semantically related but physically distant code snippets. For instance, an insecure configuration setting in a config.py file (e.g., JWT\_VERIFY\_SIGNATURE \= False) is semantically linked to the JWT processing logic in a separate auth.py file. While syntactically disconnected, their embeddings might be close in the vector space. During the exploitability verification phase, a retrieval system could pull both of these related chunks, providing the LLM with the cross-file context needed to identify a critical Security Misconfiguration or Broken Authentication vulnerability. This is also highly relevant for complex Broken Access Control and IDOR vulnerabilities where permission checks might be defined far from the resource access logic.

#### **Drawbacks**

The effectiveness of this sophisticated approach is highly dependent on the quality of the underlying AI models and can be computationally demanding.

* **Dependence on Embedding Model Quality:** The entire strategy's success is contingent on the quality and nuance of the code embedding model. A generic text-embedding model may fail to capture the subtle but critical semantic differences in code (e.g., the difference between \== and \=== in JavaScript). A high-quality, code-native model is essential, and the performance will vary significantly across different programming languages and paradigms.9  
* **Computational Intensity:** This is a computationally expensive process. It requires running a deep learning model to generate an embedding for every small unit of code and then performing numerous similarity calculations. The overall cost can be comparable to, or even exceed, that of AST parsing, especially when using large, high-quality embedding models.1  
* **Potential to Ignore Syntactic Structure:** The focus on semantic similarity can sometimes come at the expense of syntactic correctness. The algorithm might group lines of code from different functions or scopes if they are semantically related, potentially creating a chunk that is syntactically invalid or confusing for the analysis LLM to parse.

#### **When to Use**

Embedding-based chunking is best viewed not as a replacement for AST-based chunking, but as a powerful complementary technique for advanced analysis. These two strategies are not competitors; they capture two distinct and equally important dimensions of code: ASTs capture the *syntactic structure* (how the code is built), while embeddings capture the *semantic similarity* (what the code does).  
A highly effective, hybrid system would leverage this symbiotic relationship. It would first use AST parsing to create a canonical library of syntactically valid, self-contained chunks (functions, classes). Then, it would generate an embedding for each of these complete logical units. This creates a semantic graph of the entire codebase, where nodes are functions and the edges are weighted by their semantic similarity. This architecture, inspired by methodologies in advanced research like the Savant project 45, allows the scanner to perform multi-faceted analysis. It can analyze a function in isolation (thanks to the AST chunk) and simultaneously reason about its relationship to other, similar functions across the repository (thanks to the embeddings), enabling the detection of systemic, architectural flaws.  
Therefore, embedding-based chunking should be used:

* As a **secondary or complementary strategy** layered on top of a primary, structure-aware method like AST chunking.  
* In a "deep audit" or "architectural analysis" mode, where the objective is to uncover complex, non-local vulnerabilities such as intricate access control bypasses, systemic misconfigurations, or flaws arising from the subtle interactions of multiple, loosely coupled components.  
* For auxiliary tasks like code clone detection, which helps identify all instances of a vulnerability once a single instance has been found, or for building a semantic search capability over the codebase.

## **The Autonomous Frontier: Agentic Chunking**

Agentic chunking represents the most advanced and experimental frontier in data preprocessing for LLMs. It shifts the paradigm from using predefined rules or algorithms to leveraging the reasoning capabilities of an LLM itself to make autonomous, intelligent decisions about how to segment the code for analysis.

#### **Mechanism and Potential**

In this strategy, an LLM-based agent is tasked with the process of chunking.26 Instead of following a fixed procedure, the agent is given a high-level goal, such as, "Chunk this Python repository in a way that best exposes potential SQL injection vulnerabilities." The agent can then orchestrate a series of actions to achieve this goal. For example, it might:

1. Invoke an AST parser to identify all functions that contain database-related calls.  
2. Analyze the call graph to trace data flows into these functions.  
3. Reason that for a specific function, the context from its calling function is critical for analysis.  
4. Dynamically decide to merge the AST-derived chunks for the caller and callee functions into a single, larger "super-chunk" tailored specifically for the task of SQL injection detection.4

This approach mirrors the dynamic, iterative reasoning process seen in advanced agentic frameworks for cybersecurity, such as CyberRAG, where an agent can re-query its knowledge base and refine its understanding of a threat in real-time.48 This fundamentally blurs the line between preprocessing and analysis. In all other strategies, chunking is a distinct, preliminary step. With agentic chunking, the chunking process  
*is* a form of analysis. To decide how to best chunk for a specific vulnerability, the agent must possess a preliminary understanding of that vulnerability's patterns, performing a high-level analysis to inform its chunking decisions. This creates a powerful recursive loop: analysis informs chunking, which in turn enables deeper analysis.

#### **Benefits**

The potential advantages of a well-implemented agentic chunker are significant, offering a level of sophistication unattainable by static methods.

* **Task-Specific and Dynamic Adaptation:** The core benefit is the ability to create bespoke chunks optimized for detecting a specific class of vulnerability. An agent could learn that for detecting reflected XSS in a JavaScript framework like React, it is crucial to include not just the component receiving the props but also the parent component that sources the data. It could then generate a custom chunk containing both, providing the analysis LLM with the complete data propagation path.47  
* **Potential for Learning and Improvement:** A sophisticated agentic system could be designed to learn from the outcomes of the vulnerability scanner. By analyzing which chunking decisions led to the successful detection of true positives and which resulted in false negatives, the agent could refine its internal strategies over time, becoming progressively more effective with experience.50

#### **Drawbacks**

The power and flexibility of agentic chunking come with substantial complexity, cost, and novel security risks.

* **Extreme Complexity and Computational Cost:** This is by a significant margin the most complex and computationally expensive chunking strategy. It requires multiple, often chained, LLM calls just for the preprocessing phase, before the primary analysis LLM is even invoked. This can dramatically increase the cost and latency of a scan.17  
* **Potential for Misinterpretation and Hallucination:** The performance of the entire system is contingent on the reliability of the chunking agent. If the agent misinterprets its instructions or suffers from model "hallucination," it could produce nonsensical, counterproductive, or incomplete chunks that actively hinder vulnerability detection. The agent's logic requires extensive development, fine-tuning, and the implementation of robust guardrails to ensure its decisions are sound.17  
* **Introduction of a Novel Attack Surface:** The agentic chunker itself becomes a potential vector for attack. Malicious actors could target the agent with sophisticated prompt injection or data poisoning attacks. For example, an attacker could commit code with specially crafted comments designed to trick the agent into excluding a vulnerable function from any chunk, effectively hiding it from the scanner. This turns a component of the security tool into a new vulnerability.53

A fascinating paradox emerges with this strategy. While agentic systems can be opaque "black boxes," a well-designed agentic chunker could theoretically be prompted to *explain* its decisions. Unlike a traditional chunker, which provides no justification for its boundaries, an agent could attach metadata to its output, such as: "This chunk was created by merging getUserInput() and buildQuery() because my analysis indicates a direct data flow from a user-controlled source to a database sink, a pattern relevant for SQL injection detection." This transforms the chunking process from a silent utility into an active, explainable participant in the security analysis, potentially improving the interpretability of the final findings for human review.

#### **When to Use**

Given its current state of development, high cost, and inherent risks, agentic chunking is not yet suitable for widespread, real-time production scanning. Its application should be strategic and targeted.

* It is best suited for **cutting-edge research and highly specialized, offline security audits** where depth of analysis is prioritized over speed and cost.  
* It could be effectively deployed in a **"Tier 2" or "escalation" analysis workflow.** After an initial, high-speed scan using a more deterministic method like AST-based chunking identifies a high-risk file or module, the system could trigger an agentic chunker to perform a more intensive, targeted re-chunking and deep-dive analysis of that specific, limited section of the code.

## **Synthesis, Recommendations, and Hybrid Models**

The selection of a chunking strategy is not a one-size-fits-all decision but a critical architectural trade-off between computational efficiency, implementation complexity, and the semantic and syntactic integrity of the analytical units provided to the LLM. For the high-stakes domain of vulnerability scanning, where accuracy and reliability are paramount, strategies that prioritize contextual integrity are unequivocally superior.

### **A. Comparative Framework**

The following table synthesizes the analysis of the six strategies, providing a comparative framework to guide architectural decisions. It evaluates each strategy across key dimensions relevant to building an AI-powered vulnerability scanner.

| Strategy | Mechanism | Syntactic Integrity | Semantic Cohesion | Computational Cost | Implementation Complexity | Best For Vulnerability Types | Worst For Vulnerability Types |
| :---- | :---- | :---- | :---- | :---- | :---- | :---- | :---- |
| **Fixed-Size** | Splits code into chunks of a fixed character/token count. | Very Low | Very Low | Very Low | Very Low | Hardcoded Secrets, Simple Misconfigurations | SQLi, XSS, Path Traversal, Command Injection, SSRF, IDOR (any data-flow vulnerability) |
| **Sliding Window** | Creates overlapping chunks of a fixed size. | Low | Low | Low | Low | Simple Reflected XSS, vulnerabilities with very localized source/sink | Vulnerabilities spanning large functions or multiple functions |
| **Recursive** | Splits code hierarchically using a prioritized list of textual separators. | Medium | Medium | Low-Medium | Low-Medium | Misconfigurations in structured files (YAML, JSON), vulnerabilities in well-formatted scripting code | Vulnerabilities in code with complex nesting or inconsistent formatting |
| **AST-Based** | Parses code into an Abstract Syntax Tree and chunks along logical units (functions, classes). | Very High | High | Medium-High | High | SQLi, XSS, Path Traversal, Command Injection, SSRF, IDOR, Broken Access Control | Very large monolithic functions that exceed context windows (requires recursive AST splitting) |
| **Embedding-Based** | Groups small code units (e.g., lines) based on their semantic similarity. | Medium | Very High | High | High | Security Misconfiguration (non-local), Broken Access Control, IDOR (architectural patterns) | Vulnerabilities dependent on precise syntactic structure; can create syntactically invalid chunks |
| **Agentic** | Uses an LLM agent to dynamically decide how to chunk code for a specific task. | Variable | Variable | Very High | Very High | Highly complex, targeted analysis of specific vulnerability classes (in theory) | Unreliable for general-purpose scanning due to cost, complexity, and potential for error |

### **B. Strategic Guidance for Implementation**

Based on this analysis, a tiered approach to implementation is recommended, aligning the choice of strategy with the specific goals of the scanning context:

1. **For rapid, preliminary checks (e.g., in a pre-commit hook or a fast CI/CD pipeline stage):**  
   * **Start with Recursive Chunking.** Utilize language-specific splitters that recognize function and class boundaries as high-priority separators. This offers a significant improvement over fixed-size methods with minimal computational overhead, providing a reasonable balance of speed and coherence for a first-pass check.  
2. **For the core, high-accuracy analysis engine (e.g., for nightly scans, security audits, or the main scanner product):**  
   * **AST-Based Chunking is the mandatory foundation.** The preservation of syntactic integrity is non-negotiable for reliably detecting the majority of critical, data-flow-dependent vulnerabilities. The upfront investment in implementing and maintaining language parsers is justified by the profound increase in detection accuracy and the reduction of false negatives.  
3. **To augment deep analysis with architectural and cross-file insights:**  
   * **Layer Embedding-Based analysis on top of AST-generated chunks.** After creating a repository of syntactically correct function and class chunks, generate embeddings for each. This enables the discovery of non-local semantic relationships, which is crucial for identifying systemic flaws like widespread Security Misconfigurations or complex Broken Access Control schemes.  
4. **For cutting-edge research or targeted, expert-level deep dives:**  
   * **Deploy Agentic Chunking selectively.** Use the primary AST-based scan to identify a high-risk module or a potentially complex vulnerability. Then, deploy an agentic chunker to perform an exhaustive, targeted re-analysis of that specific code region, allowing it to dynamically construct the optimal context for the analysis LLM.

### **C. The Power of Hybridization: A Proposed Multi-Pass Architecture**

The most robust and effective architecture for an AI-powered vulnerability scanner will not rely on a single chunking strategy but will instead employ a hybrid, multi-pass model that synergistically combines the strengths of the most powerful techniques.8 This approach ensures that the LLM is provided with a rich, multi-faceted understanding of the code for its analysis.  
A recommended state-of-the-art architecture would be:

* **Pass 1: Syntactic Structuring (AST Parsing):** The entire codebase is first processed by a suite of language-specific parsers (e.g., using tree-sitter). The output is a structured library of syntactically complete, self-contained chunks corresponding to every function, method, and class in the repository. This creates the "ground truth" of logical code units, forming the primary basis for analysis.36  
* **Pass 2: Semantic Relationship Mapping (Embedding):** A code-native embedding model is used to generate a vector representation for every logical chunk created in Pass 1\. These embeddings are then stored in a vector database, indexed against their corresponding chunk. This process effectively creates a semantic graph of the entire codebase, where nodes are functions/classes and the distances between them represent their conceptual similarity. This enables powerful semantic search capabilities beyond simple text matching.57  
* **Pass 3: Context-Augmented Analysis (LLM):** When the system schedules a chunk for analysis by the primary LLM, it doesn't just send the chunk's code in isolation. The RAG component performs a multi-modal retrieval process:  
  1. It retrieves the target chunk's source code (from Pass 1).  
  2. It queries the vector database (from Pass 2\) to find the top k most semantically similar chunks from elsewhere in the codebase.  
  3. It retrieves the parent context of the target chunk (e.g., the class definition if the chunk is a method).  
     This retrieved information is assembled into a rich, context-aware prompt. The analysis LLM receives not only the syntactically complete code of the function under review but also examples of similar functions and its containing class structure. This hybrid approach, inspired by advanced methodologies like that of the Savant framework 45, provides the LLM with both syntactic completeness and deep semantic context, maximizing its ability to detect complex and non-obvious vulnerabilities.

### **D. Future Trajectory: The Impact of Evolving Model Architectures**

The landscape of LLM capabilities is evolving rapidly, particularly with respect to context window sizes.9 As models with context windows of millions of tokens become commonplace, the immediate pressure to chunk code into small segments to avoid exceeding limits will diminish. However, this does not render chunking obsolete; rather, it shifts the nature of the problem.  
The challenge will transition from "how do we fit the code into the context window?" to "of the entire multi-million-line codebase, which 200,000-token segment is the most relevant one to analyze for this specific vulnerability?" The sheer size of the context window will make the signal-to-noise problem even more acute. In this future state, the importance of structure-aware and semantic analysis techniques will be elevated. AST-based parsing and embedding-based similarity search will become indispensable "first-pass filters" or "retrieval" mechanisms. They will be used to intelligently identify and retrieve the most promising large, multi-function chunks from the repository to feed into the massive context window of the analysis LLM. The fundamental principles of understanding code's syntactic structure and semantic relationships will remain the cornerstones of effective AI-driven security analysis, regardless of the size of the context window.

#### **Works cited**

1. 5 Chunking Techniques for Retrieval-Augmented Generation (RAG), accessed July 30, 2025, [https://apxml.com/posts/rag-chunking-strategies-explained](https://apxml.com/posts/rag-chunking-strategies-explained)  
2. 7 Chunking Strategies in RAG You Need To Know \- F22 Labs, accessed July 30, 2025, [https://www.f22labs.com/blogs/7-chunking-strategies-in-rag-you-need-to-know/](https://www.f22labs.com/blogs/7-chunking-strategies-in-rag-you-need-to-know/)  
3. Finding the Best Chunking Strategy for Accurate AI Responses | NVIDIA Technical Blog, accessed July 30, 2025, [https://developer.nvidia.com/blog/finding-the-best-chunking-strategy-for-accurate-ai-responses/](https://developer.nvidia.com/blog/finding-the-best-chunking-strategy-for-accurate-ai-responses/)  
4. Five Levels of Chunking Strategies in RAG| Notes from Greg's Video | by Anurag Mishra, accessed July 30, 2025, [https://medium.com/@anuragmishra\_27746/five-levels-of-chunking-strategies-in-rag-notes-from-gregs-video-7b735895694d](https://medium.com/@anuragmishra_27746/five-levels-of-chunking-strategies-in-rag-notes-from-gregs-video-7b735895694d)  
5. Fixed-size, Semantic and Recursive Chunking Strategies for LLMs \- Langformers Blog, accessed July 30, 2025, [https://blog.langformers.com/llm-chunking-strategies/](https://blog.langformers.com/llm-chunking-strategies/)  
6. Challenges in RAG Applications and Comparison of Chunking Strategies \- Medium, accessed July 30, 2025, [https://medium.com/@tubelwj/challenges-in-rag-applications-and-comparison-of-chunking-strategies-390ea525ca76](https://medium.com/@tubelwj/challenges-in-rag-applications-and-comparison-of-chunking-strategies-390ea525ca76)  
7. 8 Types of Chunking for RAG Systems \- Analytics Vidhya, accessed July 30, 2025, [https://www.analyticsvidhya.com/blog/2025/02/types-of-chunking-for-rag-systems/](https://www.analyticsvidhya.com/blog/2025/02/types-of-chunking-for-rag-systems/)  
8. Mastering Document Chunking Strategies for Retrieval-Augmented Generation (RAG) | by Sahin Ahmed, Data Scientist | Medium, accessed July 30, 2025, [https://medium.com/@sahin.samia/mastering-document-chunking-strategies-for-retrieval-augmented-generation-rag-c9c16785efc7](https://medium.com/@sahin.samia/mastering-document-chunking-strategies-for-retrieval-augmented-generation-rag-c9c16785efc7)  
9. Chunking Strategies for LLM Applications \- Pinecone, accessed July 30, 2025, [https://www.pinecone.io/learn/chunking-strategies/](https://www.pinecone.io/learn/chunking-strategies/)  
10. Mastering RAG: Advanced Chunking Techniques for LLM Applications \- Galileo AI, accessed July 30, 2025, [https://galileo.ai/blog/mastering-rag-advanced-chunking-techniques-for-llm-applications](https://galileo.ai/blog/mastering-rag-advanced-chunking-techniques-for-llm-applications)  
11. Develop a RAG Solution \- Chunking Phase \- Azure Architecture Center | Microsoft Learn, accessed July 30, 2025, [https://learn.microsoft.com/en-us/azure/architecture/ai-ml/guide/rag/rag-chunking-phase](https://learn.microsoft.com/en-us/azure/architecture/ai-ml/guide/rag/rag-chunking-phase)  
12. Breaking up is hard to do: Chunking in RAG applications \- The Stack Overflow Blog, accessed July 30, 2025, [https://stackoverflow.blog/2024/12/27/breaking-up-is-hard-to-do-chunking-in-rag-applications/](https://stackoverflow.blog/2024/12/27/breaking-up-is-hard-to-do-chunking-in-rag-applications/)  
13. Pros and Cons of Different Chunking Strategies in Language Models | by Rishabh Saxena, accessed July 30, 2025, [https://medium.com/@saxena\_rishabh/pros-and-cons-of-different-chunking-strategies-in-language-models-5faf0ecaa262](https://medium.com/@saxena_rishabh/pros-and-cons-of-different-chunking-strategies-in-language-models-5faf0ecaa262)  
14. Different Types of Chunking Methods \- Metric Coders, accessed July 30, 2025, [https://www.metriccoders.com/post/different-types-of-chunking-methods](https://www.metriccoders.com/post/different-types-of-chunking-methods)  
15. Optimizing Chunking, Embedding, and Vectorization for Retrieval-Augmented Generation | by Adnan Masood, PhD. | Medium, accessed July 30, 2025, [https://medium.com/@adnanmasood/optimizing-chunking-embedding-and-vectorization-for-retrieval-augmented-generation-ea3b083b68f7](https://medium.com/@adnanmasood/optimizing-chunking-embedding-and-vectorization-for-retrieval-augmented-generation-ea3b083b68f7)  
16. RAG: Part 2: Chunking. The information is endless, and we have… | by Mehul Jain | Medium, accessed July 30, 2025, [https://medium.com/@j13mehul/rag-part-2-chunking-8b68006eefc1](https://medium.com/@j13mehul/rag-part-2-chunking-8b68006eefc1)  
17. Chunking \- IBM, accessed July 30, 2025, [https://www.ibm.com/architectures/papers/rag-cookbook/chunking](https://www.ibm.com/architectures/papers/rag-cookbook/chunking)  
18. Fixed-Length Chunking: Boost Your NLP Model's Performance | by Aditya Mangal | Medium, accessed July 30, 2025, [https://adityamangal98.medium.com/fixed-length-chunking-boost-your-nlp-models-performance-c421fde066bf](https://adityamangal98.medium.com/fixed-length-chunking-boost-your-nlp-models-performance-c421fde066bf)  
19. From Fixed-Size to NLP Chunking \- A Deep Dive into Text Chunking Techniques \- Krystian Safjan's Blog, accessed July 30, 2025, [https://safjan.com/from-fixed-size-to-nlp-chunking-a-deep-dive-into-text-chunking-techniques/](https://safjan.com/from-fixed-size-to-nlp-chunking-a-deep-dive-into-text-chunking-techniques/)  
20. AST Enables Code RAG Models to Overcome Traditional Chunking Limitations \- Medium, accessed July 30, 2025, [https://medium.com/@jouryjc0409/ast-enables-code-rag-models-to-overcome-traditional-chunking-limitations-b0bc1e61bdab](https://medium.com/@jouryjc0409/ast-enables-code-rag-models-to-overcome-traditional-chunking-limitations-b0bc1e61bdab)  
21. Comparison of chunking algorithms. (a) Fixed-size chunking is fast but... \- ResearchGate, accessed July 30, 2025, [https://www.researchgate.net/figure/Comparison-of-chunking-algorithms-a-Fixed-size-chunking-is-fast-but-has-the\_fig1\_327525835](https://www.researchgate.net/figure/Comparison-of-chunking-algorithms-a-Fixed-size-chunking-is-fast-but-has-the_fig1_327525835)  
22. A Thorough Investigation of Content-Defined Chunking Algorithms for Data Deduplication \- arXiv, accessed July 30, 2025, [https://arxiv.org/pdf/2409.06066](https://arxiv.org/pdf/2409.06066)  
23. Sliding Window in RAG: Step-by-Step Guide | newline \- Newline.co, accessed July 30, 2025, [https://www.newline.co/@zaoyang/sliding-window-in-rag-step-by-step-guide--c4c786c6](https://www.newline.co/@zaoyang/sliding-window-in-rag-step-by-step-guide--c4c786c6)  
24. SlidingWindow provides an interface to retrieve chunks from a byte array using a sliding window. \- GitHub, accessed July 30, 2025, [https://github.com/jchristn/SlidingWindow](https://github.com/jchristn/SlidingWindow)  
25. Chunk large documents for vector search solutions in Azure AI Search \- Microsoft Learn, accessed July 30, 2025, [https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-chunk-documents](https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-chunk-documents)  
26. Chunking strategies for RAG tutorial using Granite \- IBM, accessed July 30, 2025, [https://www.ibm.com/think/tutorials/chunking-strategies-for-rag-with-langchain-watsonx-ai](https://www.ibm.com/think/tutorials/chunking-strategies-for-rag-with-langchain-watsonx-ai)  
27. What Is Agentic Chunking? \- IBM, accessed July 30, 2025, [https://www.ibm.com/think/topics/agentic-chunking](https://www.ibm.com/think/topics/agentic-chunking)  
28. Chunking Methods: All to know about it | by Abhirami V S \- Medium, accessed July 30, 2025, [https://medium.com/@AbhiramiVS/chunking-methods-all-to-know-about-it-65c10aa7b24e](https://medium.com/@AbhiramiVS/chunking-methods-all-to-know-about-it-65c10aa7b24e)  
29. 7 Chunking Strategies for Langchain | by Anix Lynch, MBA, ex-VC | Medium, accessed July 30, 2025, [https://medium.com/@anixlynch/7-chunking-strategies-for-langchain-b50dac194813](https://medium.com/@anixlynch/7-chunking-strategies-for-langchain-b50dac194813)  
30. Evaluating Chunking Strategies for Retrieval \- Chroma Research, accessed July 30, 2025, [https://research.trychroma.com/evaluating-chunking](https://research.trychroma.com/evaluating-chunking)  
31. Abstract Syntax Tree (AST) \- Explained in Plain English \- DEV Community, accessed July 30, 2025, [https://dev.to/balapriya/abstract-syntax-tree-ast-explained-in-plain-english-1h38](https://dev.to/balapriya/abstract-syntax-tree-ast-explained-in-plain-english-1h38)  
32. cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree \- arXiv, accessed July 30, 2025, [https://arxiv.org/html/2506.15655v1](https://arxiv.org/html/2506.15655v1)  
33. Abstract syntax tree \- Wikipedia, accessed July 30, 2025, [https://en.wikipedia.org/wiki/Abstract\_syntax\_tree](https://en.wikipedia.org/wiki/Abstract_syntax_tree)  
34. cAST: Enhancing Code Retrieval-Augmented Generation ... \- arXiv, accessed July 30, 2025, [https://arxiv.org/pdf/2506.15655](https://arxiv.org/pdf/2506.15655)  
35. ilanaliouchouche/ASTSnowballSplitter: An effective way for optimal code segmentation in AI coding assistants systems (https://pypi.org/project/astsnowballsplitter) \- GitHub, accessed July 30, 2025, [https://github.com/ilanaliouchouche/ASTSnowballSplitter](https://github.com/ilanaliouchouche/ASTSnowballSplitter)  
36. Enhancing LLM Code Generation with RAG and AST-Based Chunking | by VXRL \- Medium, accessed July 30, 2025, [https://vxrl.medium.com/enhancing-llm-code-generation-with-rag-and-ast-based-chunking-5b81902ae9fc](https://vxrl.medium.com/enhancing-llm-code-generation-with-rag-and-ast-based-chunking-5b81902ae9fc)  
37. Which chunker to utilize for code based data \- Intermediate \- Hugging Face Forums, accessed July 30, 2025, [https://discuss.huggingface.co/t/which-chunker-to-utilize-for-code-based-data/145376](https://discuss.huggingface.co/t/which-chunker-to-utilize-for-code-based-data/145376)  
38. Detecting SQL injections in Python code using AST | Artem Golubin, accessed July 30, 2025, [https://rushter.com/blog/detecting-sql-injections-in-python/](https://rushter.com/blog/detecting-sql-injections-in-python/)  
39. Abstract Syntax Tree for Programming Language Understanding and Representation: How Far Are We? \- arXiv, accessed July 30, 2025, [https://arxiv.org/html/2312.00413v1](https://arxiv.org/html/2312.00413v1)  
40. On the Complexity and Performance of Parsing with Derivatives | Hacker News, accessed July 30, 2025, [https://news.ycombinator.com/item?id=11976769](https://news.ycombinator.com/item?id=11976769)  
41. FuncVul: An Effective Function Level Vulnerability Detection Model using LLM and Code Chunk \- arXiv, accessed July 30, 2025, [https://arxiv.org/html/2506.19453v1](https://arxiv.org/html/2506.19453v1)  
42. Codebase Embedding \- Beginners \- Hugging Face Forums, accessed July 30, 2025, [https://discuss.huggingface.co/t/codebase-embedding/137026](https://discuss.huggingface.co/t/codebase-embedding/137026)  
43. Chunking Analysis: Which is the right chunking approach for your language? \- LanceDB, accessed July 30, 2025, [https://www.lancedb.com/blog/chunking-analysis-which-is-the-right-chunking-approach-for-your-language/](https://www.lancedb.com/blog/chunking-analysis-which-is-the-right-chunking-approach-for-your-language/)  
44. From Zero to RAG: The Art of Document Chunking and Embedding for RAG | by Jesvin K Justin | Medium, accessed July 30, 2025, [https://medium.com/@jesvinkjustin/from-zero-to-rag-the-art-of-document-chunking-and-embedding-for-rag-d9764695cc46](https://medium.com/@jesvinkjustin/from-zero-to-rag-the-art-of-document-chunking-and-embedding-for-rag-d9764695cc46)  
45. Savant: Vulnerability Detection in Application Dependencies through Semantic-Guided Reachability Analysis \- arXiv, accessed July 30, 2025, [https://arxiv.org/html/2506.17798v1](https://arxiv.org/html/2506.17798v1)  
46. SAVANT: Vulnerability Detection in Application Dependencies through Semantic-Guided Reachability Analysis \- arXiv, accessed July 30, 2025, [https://arxiv.org/pdf/2506.17798](https://arxiv.org/pdf/2506.17798)  
47. Implement agentic chunking to optimize LLM inputs with Langchain and watsonx.ai \- IBM, accessed July 30, 2025, [https://www.ibm.com/think/tutorials/use-agentic-chunking-to-optimize-llm-inputs-with-langchain-watsonx-ai](https://www.ibm.com/think/tutorials/use-agentic-chunking-to-optimize-llm-inputs-with-langchain-watsonx-ai)  
48. CyberRAG: An agentic RAG cyber attack classification and reporting tool \- arXiv, accessed July 30, 2025, [https://arxiv.org/html/2507.02424v1](https://arxiv.org/html/2507.02424v1)  
49. CyberRAG: An agentic RAG cyber attack classification and ... \- arXiv, accessed July 30, 2025, [https://arxiv.org/pdf/2507.02424](https://arxiv.org/pdf/2507.02424)  
50. Agentic AI for Cybersecurity: Real life Use Cases & Examples \- Research AIMultiple, accessed July 30, 2025, [https://research.aimultiple.com/agentic-ai-cybersecurity/](https://research.aimultiple.com/agentic-ai-cybersecurity/)  
51. An Introduction Agentic AI in Cybersecurity, accessed July 30, 2025, [https://www.cybersecuritytribe.com/articles/an-introduction-agentic-ai-in-cybersecurity](https://www.cybersecuritytribe.com/articles/an-introduction-agentic-ai-in-cybersecurity)  
52. Report warns of agentic AI cyber risks \- Route Fifty, accessed July 30, 2025, [https://www.route-fifty.com/artificial-intelligence/2025/06/report-warns-agentic-ai-cyber-risks/405874/](https://www.route-fifty.com/artificial-intelligence/2025/06/report-warns-agentic-ai-cyber-risks/405874/)  
53. The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover \- arXiv, accessed July 30, 2025, [https://arxiv.org/pdf/2507.06850](https://arxiv.org/pdf/2507.06850)  
54. Generative AI Cybersecurity Risks for Business AI Agent Workflows | by Valdez Ladd, accessed July 30, 2025, [https://medium.com/@oracle\_43885/generative-ai-cybersecurity-risks-for-business-agentic-workflows-d029a3844732](https://medium.com/@oracle_43885/generative-ai-cybersecurity-risks-for-business-agentic-workflows-d029a3844732)  
55. The massive, no-good concerns around agentic AI cybersecurity \- Tech Monitor, accessed July 30, 2025, [https://www.techmonitor.ai/technology/cybersecurity/agentic-ai-cybersecurity-implications](https://www.techmonitor.ai/technology/cybersecurity/agentic-ai-cybersecurity-implications)  
56. A Guide to Chunking Strategies for Retrieval Augmented Generation (RAG) \- Zilliz Learn, accessed July 30, 2025, [https://zilliz.com/learn/guide-to-chunking-strategies-for-rag](https://zilliz.com/learn/guide-to-chunking-strategies-for-rag)  
57. Embedding content in PostgreSQL using Python: Combining markup chunking and token-aware chunking \- Fujitsu Enterprise Postgres, accessed July 30, 2025, [https://www.postgresql.fastware.com/blog/embedding-content-in-postgresql-using-python](https://www.postgresql.fastware.com/blog/embedding-content-in-postgresql-using-python)  
58. CSGVD: A deep learning approach combining sequence and graph embedding for source code vulnerability detection \- ResearchGate, accessed July 30, 2025, [https://www.researchgate.net/publication/367592841\_CSGVD\_A\_deep\_learning\_approach\_combining\_sequence\_and\_graph\_embedding\_for\_source\_code\_vulnerability\_detection](https://www.researchgate.net/publication/367592841_CSGVD_A_deep_learning_approach_combining_sequence_and_graph_embedding_for_source_code_vulnerability_detection)